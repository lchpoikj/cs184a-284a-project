{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:01.474657Z",
     "start_time": "2023-12-09T05:26:01.464808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'mps'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def process(multi_series):\n",
    "  multi_series[\"timestamp\"] = pd.to_datetime(multi_series[\"timestamp\"],utc=True)\n",
    "  multi_series[\"hour\"] = multi_series[\"timestamp\"].dt.hour\n",
    "  multi_series[\"anglez_times_enmo\"] = multi_series[\"anglez\"] * multi_series[\"enmo\"]\n",
    "  multi_series[\"anglez_max\"] = multi_series.groupby(\"series_id\")[\"anglez\"].transform('max')\n",
    "  multi_series[\"anglez_min\"] = multi_series.groupby(\"series_id\")[\"anglez\"].transform('min')\n",
    "  multi_series[\"enmo_max\"] = multi_series.groupby(\"series_id\")[\"enmo\"].transform('max')\n",
    "  return multi_series\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:02.641339Z",
     "start_time": "2023-12-09T05:26:02.631528Z"
    }
   },
   "id": "4d01d36123f8ca8d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(2844900, 11)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_ids = ['08db4255286f', '0a96f4993bd7', '0cfc06c129cc', '1087d7b0ff2e', '10f8bc1f7b07', '18b61dd5aae8', '29c75c018220', '31011ade7c0a']\n",
    "multi_series = pd.read_parquet(\"Zzzs_train.parquet\", filters=[('series_id','in',series_ids)])\n",
    "\n",
    "\n",
    "multi_series = process(multi_series)\n",
    "multi_series.head()\n",
    "\n",
    "multi_series.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:10.510931Z",
     "start_time": "2023-12-09T05:26:03.351247Z"
    }
   },
   "id": "c098276eff495cbd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/chenhanlyu/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df_train_X_scaled = scaler.fit_transform(multi_series[[\"step\", \"hour\",\"anglez\",\"enmo\",\"anglez_times_enmo\", \"anglez_max\", \"anglez_min\", \"enmo_max\"]])\n",
    "\n",
    "df_train_y = multi_series[\"awake\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:11.546758Z",
     "start_time": "2023-12-09T05:26:11.371245Z"
    }
   },
   "id": "f87e20b9c64b9a48"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "Xtr, Xva, ytr, yva = train_test_split(df_train_X_scaled, df_train_y, shuffle = False)\n",
    "\n",
    "Xtr = tensor(Xtr, dtype=torch.float32).to(device)\n",
    "Xva = tensor(Xva, dtype=torch.float32).to(device)\n",
    "# print(ytr, yva)\n",
    "ytr = tensor(ytr.values, dtype=torch.float32).to(device)\n",
    "yva = tensor(yva.values, dtype=torch.float32).to(device)\n",
    "Xtr.shape, Xva.shape, ytr.shape, yva.shape\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_dataset = MyDataset(Xtr, ytr)\n",
    "valid_dataset = MyDataset(Xva, yva)\n",
    "\n",
    "batch_size = 288  #tried 50, 100, 300\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:12.489347Z",
     "start_time": "2023-12-09T05:26:12.413374Z"
    }
   },
   "id": "939220d3c5143db3"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20 \n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 288\n",
    "\n",
    "INPUT_SIZE = 8\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:13.677709Z",
     "start_time": "2023-12-09T05:26:13.675579Z"
    }
   },
   "id": "aa6bbd8fd8ff90da"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, 128, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:14.533826Z",
     "start_time": "2023-12-09T05:26:14.530643Z"
    }
   },
   "id": "432228dc2208e716"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "LSTMModel(\n  (lstm): LSTM(8, 128, num_layers=2, batch_first=True)\n  (lstm2): LSTM(128, 128, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=128, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(INPUT_SIZE,HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE).to(device)\n",
    "model.load_state_dict(torch.load(\"models/LSTMwithzzz.model\"))\n",
    "model.eval()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:26:15.921665Z",
     "start_time": "2023-12-09T05:26:15.895791Z"
    }
   },
   "id": "e1f4b4210c814d75"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.00988997855812157"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_target = []\n",
    "y_prob = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "     for i, (X_train, y_valid) in enumerate(valid_loader):\n",
    "        output = model(X_train).cpu()\n",
    "        y_pred_p = output\n",
    "        y_pred_tag = (output>0.5).int()\n",
    "        y_prob.append(y_pred_p.detach().numpy())\n",
    "        y_pred.append(y_pred_tag.detach().numpy())\n",
    "        y_target.append(y_valid.cpu().detach().numpy())\n",
    "\n",
    "y_pred = [a.squeeze().tolist() for a in y_pred]\n",
    "y_pred = list(itertools.chain.from_iterable(y_pred))\n",
    "y_target = [a.squeeze().tolist() for a in y_target]\n",
    "y_target = list(itertools.chain.from_iterable(y_target))\n",
    "y_prob = [a.squeeze().tolist() for a in y_prob]\n",
    "y_prob = list(itertools.chain.from_iterable(y_prob))\n",
    "\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "zero_one_loss(y_target, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T04:33:30.761208Z",
     "start_time": "2023-12-09T04:32:39.321388Z"
    }
   },
   "id": "fdb90a4cb52912f2"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2bf38fa1eb2cd806"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from metric import score\n",
    "\n",
    "test_info = multi_series[2133675:2844900]\n",
    "\n",
    "def moving_average_filter(lst, window_size):\n",
    "    # Applying a simple moving average filter\n",
    "    smoothed = []\n",
    "    for i in range(len(lst)):\n",
    "        start = max(i - window_size // 2, 0)\n",
    "        end = min(i + window_size // 2 + 1, len(lst))\n",
    "        smoothed.append(round(sum(lst[start:end]) / (end - start)))\n",
    "    return smoothed\n",
    "\n",
    "y_pred = moving_average_filter(y_pred, int(2*60*60/5))\n",
    "\n",
    "def find_change_points(lst):\n",
    "    change_points = []\n",
    "    change_points_events = []\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i-1]:\n",
    "            change_points.append(i)\n",
    "            if lst[i] == 0:\n",
    "                change_points_events.append(\"onset\")\n",
    "            else:\n",
    "                change_points_events.append(\"wakeup\")\n",
    "    return change_points, change_points_events\n",
    "\n",
    "# predicted_event = return_event(test_info, y_pred, y_prob)\n",
    "index_points, event = find_change_points(y_pred)\n",
    "# print(event)\n",
    "detected_event = test_info.iloc[index_points][[\"series_id\", \"step\", \"timestamp\"]]\n",
    "\n",
    "\n",
    "confident_score = [] #since use change point detection by hard switch, we confirm the score to be 1\n",
    "\n",
    "for i in range(len(event)):\n",
    "    confident_score.append(1)\n",
    "\n",
    "\n",
    "detected_event[\"event\"] = event\n",
    "detected_event[\"score\"] = confident_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T04:33:52.511206Z",
     "start_time": "2023-12-09T04:33:43.643904Z"
    }
   },
   "id": "a589d1e8526c255d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "            series_id    step                 timestamp   event  score\n2139562  18b61dd5aae8  254422 2018-01-06 14:51:50+00:00  wakeup      1\n2148680  18b61dd5aae8  263540 2018-01-07 03:31:40+00:00   onset      1\n2154779  18b61dd5aae8  269639 2018-01-07 11:59:55+00:00  wakeup      1\n2167959  18b61dd5aae8  282819 2018-01-08 06:18:15+00:00   onset      1\n2174045  18b61dd5aae8  288905 2018-01-08 14:45:25+00:00  wakeup      1\n...               ...     ...                       ...     ...    ...\n2791551  29c75c018220  410871 2018-04-28 11:09:15+00:00  wakeup      1\n2803198  29c75c018220  422518 2018-04-29 03:19:50+00:00   onset      1\n2809058  29c75c018220  428378 2018-04-29 11:28:10+00:00  wakeup      1\n2820960  29c75c018220  440280 2018-04-30 04:00:00+00:00   onset      1\n2826070  29c75c018220  445390 2018-04-30 11:05:50+00:00  wakeup      1\n\n[81 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>step</th>\n      <th>timestamp</th>\n      <th>event</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2139562</th>\n      <td>18b61dd5aae8</td>\n      <td>254422</td>\n      <td>2018-01-06 14:51:50+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2148680</th>\n      <td>18b61dd5aae8</td>\n      <td>263540</td>\n      <td>2018-01-07 03:31:40+00:00</td>\n      <td>onset</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2154779</th>\n      <td>18b61dd5aae8</td>\n      <td>269639</td>\n      <td>2018-01-07 11:59:55+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2167959</th>\n      <td>18b61dd5aae8</td>\n      <td>282819</td>\n      <td>2018-01-08 06:18:15+00:00</td>\n      <td>onset</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2174045</th>\n      <td>18b61dd5aae8</td>\n      <td>288905</td>\n      <td>2018-01-08 14:45:25+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2791551</th>\n      <td>29c75c018220</td>\n      <td>410871</td>\n      <td>2018-04-28 11:09:15+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2803198</th>\n      <td>29c75c018220</td>\n      <td>422518</td>\n      <td>2018-04-29 03:19:50+00:00</td>\n      <td>onset</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2809058</th>\n      <td>29c75c018220</td>\n      <td>428378</td>\n      <td>2018-04-29 11:28:10+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2820960</th>\n      <td>29c75c018220</td>\n      <td>440280</td>\n      <td>2018-04-30 04:00:00+00:00</td>\n      <td>onset</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2826070</th>\n      <td>29c75c018220</td>\n      <td>445390</td>\n      <td>2018-04-30 11:05:50+00:00</td>\n      <td>wakeup</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_id_column_name = \"series_id\"\n",
    "time_column_name = \"step\"\n",
    "event_column_name = \"event\"\n",
    "score_column_name = \"score\"\n",
    "valid_event = pd.read_csv(\"zzz_validevent.csv\")\n",
    "detected_event"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T04:33:54.959368Z",
     "start_time": "2023-12-09T04:33:54.926124Z"
    }
   },
   "id": "59d57a1b7445cc2b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       series_id  night   event    step                 timestamp\n0   18b61dd5aae8     15  wakeup  254292  2018-01-06T09:41:00-0500\n1   18b61dd5aae8     16   onset  263424  2018-01-06T22:22:00-0500\n2   18b61dd5aae8     16  wakeup  269856  2018-01-07T07:18:00-0500\n3   18b61dd5aae8     17   onset  282864  2018-01-08T01:22:00-0500\n4   18b61dd5aae8     17  wakeup  288924  2018-01-08T09:47:00-0500\n..           ...    ...     ...     ...                       ...\n76  29c75c018220     24  wakeup  410856  2018-04-28T07:08:00-0400\n77  29c75c018220     25   onset  422532  2018-04-28T23:21:00-0400\n78  29c75c018220     25  wakeup  428340  2018-04-29T07:25:00-0400\n79  29c75c018220     26   onset  440256  2018-04-29T23:58:00-0400\n80  29c75c018220     26  wakeup  445440  2018-04-30T07:10:00-0400\n\n[81 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>series_id</th>\n      <th>night</th>\n      <th>event</th>\n      <th>step</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18b61dd5aae8</td>\n      <td>15</td>\n      <td>wakeup</td>\n      <td>254292</td>\n      <td>2018-01-06T09:41:00-0500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18b61dd5aae8</td>\n      <td>16</td>\n      <td>onset</td>\n      <td>263424</td>\n      <td>2018-01-06T22:22:00-0500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18b61dd5aae8</td>\n      <td>16</td>\n      <td>wakeup</td>\n      <td>269856</td>\n      <td>2018-01-07T07:18:00-0500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18b61dd5aae8</td>\n      <td>17</td>\n      <td>onset</td>\n      <td>282864</td>\n      <td>2018-01-08T01:22:00-0500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18b61dd5aae8</td>\n      <td>17</td>\n      <td>wakeup</td>\n      <td>288924</td>\n      <td>2018-01-08T09:47:00-0500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>29c75c018220</td>\n      <td>24</td>\n      <td>wakeup</td>\n      <td>410856</td>\n      <td>2018-04-28T07:08:00-0400</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>29c75c018220</td>\n      <td>25</td>\n      <td>onset</td>\n      <td>422532</td>\n      <td>2018-04-28T23:21:00-0400</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>29c75c018220</td>\n      <td>25</td>\n      <td>wakeup</td>\n      <td>428340</td>\n      <td>2018-04-29T07:25:00-0400</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>29c75c018220</td>\n      <td>26</td>\n      <td>onset</td>\n      <td>440256</td>\n      <td>2018-04-29T23:58:00-0400</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>29c75c018220</td>\n      <td>26</td>\n      <td>wakeup</td>\n      <td>445440</td>\n      <td>2018-04-30T07:10:00-0400</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_event"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T04:33:56.848253Z",
     "start_time": "2023-12-09T04:33:56.844334Z"
    }
   },
   "id": "cd3be1a86bc9fae5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7208340713049592\n"
     ]
    }
   ],
   "source": [
    "tolerances = {\n",
    "    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 720], \n",
    "    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 720]\n",
    "}\n",
    "\n",
    "\n",
    "print(score\n",
    "(\n",
    "        valid_event,\n",
    "        detected_event,\n",
    "        tolerances,\n",
    "        series_id_column_name,\n",
    "        time_column_name,\n",
    "        event_column_name,\n",
    "        score_column_name\n",
    "        # use_scoring_intervals=True\n",
    "))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T04:34:39.425890Z",
     "start_time": "2023-12-09T04:34:39.264742Z"
    }
   },
   "id": "d355680a7059269c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1948f3ab944f0c72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
